data:
  class_path: datasets.PedestrianDataModule
  init_args:
    data_dir: "/nas/drive6/mae/freestall_multicam/TrackTacular_MultiSeq"
    batch_size: 2
    num_workers: 4
    accumulate_grad_batches: 8
    # to train an all the available data: sequences_CityU_all.json
    sequences_file: "sequences_CityU_all.json"
    resolution: [200, 4, 120]  # Y, Z, X
    bounds: [0, 120, 0, 200, 0, 20]  # xmin, xmax, ymin, ymax, zmin, zmax

model:
  # Resolution for TrackTacular
  resolution: [200, 4, 120]
  bounds: [0, 120, 0, 200, 0, 20]
  
  # âœ… CRITICAL for cross-dataset testing later
  num_cameras: null  # NOT 8! Enables variable camera support
  
  # Model architecture
  model_name: 'mvdet'
  encoder_name: 'res18'
  feat2d_dim: 128
  num_classes: 1
  z_sign: 1
  
  # Training parameters
  learning_rate: 0.001
  conf_threshold: 0.4
  max_detections: 100
  depth: [32, 250, 3250]
  
  # Temporal caching
  use_temporal_cache: true
  
  # Tracking
  use_advanced_tracking: true
  tracking_motion_model: 'adaptive'
  use_trajectory_matching: true
  use_bev_iou: true
  cattle_size: 60

trainer:
  accelerator: gpu
  devices: 1
  max_epochs: 100
  accumulate_grad_batches: 8
  gradient_clip_val: 0.5
  check_val_every_n_epoch: 5
  log_every_n_steps: 5
